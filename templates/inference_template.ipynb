{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBKyEZ6JJD12"
      },
      "source": [
        "# Nada AI Inference Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usjn1APJJD13"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NillionNetwork/nada-ai/blob/main/templates/inference_template.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcWCxWr2JD13"
      },
      "source": [
        "This notebook provides a generic & easily customizable end-to-end template for running AI model inference on the Nillion network.\n",
        "\n",
        "Feel free to customize this template to fit your use case by navigating to the cells annotated by a üìù TODO symbol!\n",
        "\n",
        "We are really excited for developers to build with our SDK, if you have any questions please do reach out to us on:\n",
        "\n",
        "[![Discord](https://img.shields.io/badge/Discord-nillionnetwork-%235865F2?logo=discord)](https://discord.gg/nillionnetwork)\n",
        "[![GitHub Discussions](https://img.shields.io/badge/GitHub_Discussions-NillionNetwork-%23181717?logo=github)](https://github.com/orgs/NillionNetwork/discussions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSDvb7RpJD13"
      },
      "source": [
        "# 1. Set up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26G7oJmJJD14"
      },
      "source": [
        "The boring part!\n",
        "\n",
        "Installs all required dependencies and spins up a local devnet that will run Nada programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJGlGcFSJD14"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nada-ai~=0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZhUaKwFIJD14"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import uuid\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.core.magic import register_cell_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PRtnZlvWJD15"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"target/\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GalpJ83JJD15"
      },
      "outputs": [],
      "source": [
        "@register_cell_magic\n",
        "def to_file(line, cell):\n",
        "    \"Writes the content of the cell to a file specified in the line argument.\"\n",
        "    filepath = Path(line.strip())\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with open(filepath, \"w\") as f:\n",
        "        f.write(cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qNsTlEsEJD15"
      },
      "outputs": [],
      "source": [
        "# Configure telemetry settings\n",
        "enable_telemetry = True  #@param {type:\"boolean\"}\n",
        "my_identifier = \"your-telemetry-identifier\"  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS5l28BkJD15",
        "outputId": "f28cb3cc-5eef-41f5-ef50-4b4320ebe5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  7810  100  7810    0     0  11984      0 --:--:-- --:--:-- --:--:-- 11978\n",
            "\n",
            "nilup has been installed into /root/.nilup/bin and added to your $PATH in /root/.bashrc.\n",
            "\n",
            "Run 'source /root/.bashrc' or start a new terminal session to use nilup.\n",
            "\n",
            "By providing your Ethereum wallet address, you consent to the collection of telemetry data by the Nillion Network.\n",
            "That includes but is not limited to\n",
            "- The version of the SDK you are using\n",
            "- The OS you are using\n",
            "- The Processor Architecture you are using\n",
            "- The SDK binary that you are running and the subcommand\n",
            "- The wallet address you provided\n",
            "- The errors produced by the SDK\n",
            "We collect this data to understand how the software is used, and to better assist you in case of issues.\n",
            "While we will not collect any personal information, we still recommend using a new wallet address that cannot be linked to your identity by any third party.\n",
            "For more information, our privacy policy is available at https://nillion.com/privacy/.\n",
            "Do you consent to the collection of telemetry data? (yes/no)\n",
            "Telemetry data collection enabled\n",
            "Installing SDK bins version latest\n",
            "Downloading latest/nillion-sdk-bins-x86_64-unknown-linux-musl.tar.gz\n",
            "SDK version latest installed\n",
            "SDK version latest set as default\n",
            "Installing SDK bins version 0.4.0\n",
            "Downloading 0.4.0/nillion-sdk-bins-x86_64-unknown-linux-musl.tar.gz\n",
            "SDK version 0.4.0 installed\n",
            "SDK version 0.4.0 set as default\n"
          ]
        }
      ],
      "source": [
        "# Install the nilup tool and then use that to install the Nillion SDK\n",
        "!curl https://nilup.nilogy.xyz/install.sh | bash\n",
        "\n",
        "# Update Path if ran in colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    os.environ[\"PATH\"] += \":/root/.nilup/bin\"\n",
        "    os.environ[\"PATH\"] += \":/root/.nilup/sdks/latest/\"\n",
        "\n",
        "# Set telemetry if opted in\n",
        "if enable_telemetry:\n",
        "    identifier = f\"nada-ai-inference-{str(uuid.uuid4())}-{my_identifier}\"\n",
        "    !echo 'yes' | nilup instrumentation enable --wallet {identifier}\n",
        "\n",
        "# Install the lastest SDK and initialise it\n",
        "!nilup init\n",
        "!nilup install 0.4.0\n",
        "!nilup use 0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPgPBxZCJD15",
        "outputId": "fc21ad6a-61ae-4fe4-ce9e-d5b06c4104f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "# Spin up local Nillion devnet\n",
        "!nohup nillion-devnet &\n",
        "\n",
        "time.sleep(20)  # Wait for devnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOXX1yzJJD15"
      },
      "source": [
        "# 2. Create a trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-97aOkvoJD15"
      },
      "source": [
        "In this next step we will create a trained model. Either by training it ourselves or by loading a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N5YTDSu3JD15"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6v859DvQJD15"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        target: str=\"label\",\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data = self.preprocess_data(data)\n",
        "\n",
        "        self.features = self.data.drop(target, axis=1).values.astype(float)\n",
        "        self.targets = self.data[target].values.astype(float)\n",
        "\n",
        "    def preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
        "        # TODO: üìù define your own preprocessing logic here\n",
        "        data.drop(\"Name\", axis=1, inplace=True)\n",
        "        data.rename(columns={\"Survived\": \"label\"}, inplace=True)\n",
        "        data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mean())\n",
        "        data = pd.get_dummies(data, dtype=\"int64\")\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return feature, target\n",
        "\n",
        "# TODO: üìù read your own dataset!\n",
        "raw_df = pd.read_csv(\n",
        "    \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
        ")\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    raw_df,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "train_dataset = MyDataset(train_df)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_dataset = MyDataset(test_df)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CPlLqmFTJD16"
      },
      "outputs": [],
      "source": [
        "# TODO: üìù make your own model or load a pre-trained one\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.Linear(7, 16)\n",
        "        self.ln2 = nn.Linear(16, 1)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.ln2(x)\n",
        "        return x\n",
        "\n",
        "my_model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFOu6crRJD16",
        "outputId": "167458b4-8f0c-4c3a-ef3c-4ac2e768cd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.682934\n",
            "Validation Accuracy: 73.5955%\n",
            "Epoch 2, Loss: 0.503592\n",
            "Validation Accuracy: 66.2921%\n",
            "Epoch 3, Loss: 0.503470\n",
            "Validation Accuracy: 74.1573%\n",
            "Epoch 4, Loss: 0.494351\n",
            "Validation Accuracy: 72.4719%\n",
            "Epoch 5, Loss: 0.497334\n",
            "Validation Accuracy: 75.2809%\n",
            "Epoch 6, Loss: 0.471730\n",
            "Validation Accuracy: 73.0337%\n",
            "Epoch 7, Loss: 0.466857\n",
            "Validation Accuracy: 75.2809%\n",
            "Epoch 8, Loss: 0.460453\n",
            "Validation Accuracy: 74.1573%\n",
            "Epoch 9, Loss: 0.448872\n",
            "Validation Accuracy: 74.7191%\n",
            "Epoch 10, Loss: 0.473686\n",
            "Validation Accuracy: 74.7191%\n"
          ]
        }
      ],
      "source": [
        "training_args = {\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"learning_rate\": 0.01,\n",
        "}\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(\n",
        "    my_model.parameters(),\n",
        "    lr=training_args[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "for epoch in range(training_args[\"num_train_epochs\"]):\n",
        "    my_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = my_model(inputs).squeeze(1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.6f}')\n",
        "\n",
        "    my_model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = torch.sigmoid(my_model(inputs))\n",
        "            predicted = torch.round(outputs).squeeze(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Validation Accuracy: {100 * correct / total:.4f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV10x90yJD16"
      },
      "source": [
        "# 3. Create Nada program that runs blind inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zFbjXrwwJD16"
      },
      "outputs": [],
      "source": [
        "%%to_file nada-project.toml\n",
        "name = \"inference\"\n",
        "version = \"0.1.0\"\n",
        "authors = [\"\"]\n",
        "\n",
        "[[programs]]\n",
        "path = \"src/inference.py\"\n",
        "prime_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fj6c74WzJD16"
      },
      "outputs": [],
      "source": [
        "%%to_file src/inference.py\n",
        "import nada_numpy as na\n",
        "\n",
        "from nada_ai import nn\n",
        "from nada_dsl import Output\n",
        "from typing import List\n",
        "\n",
        "INPUT_DIMS=(7,)\n",
        "\n",
        "# TODO: üìù implement your model using nada-ai modules\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.Linear(7, 16)\n",
        "        self.ln2 = nn.Linear(16, 1)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: na.NadaArray) -> na.NadaArray:\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.ln2(x)\n",
        "        return x\n",
        "\n",
        "def nada_main() -> List[Output]:\n",
        "    \"\"\"Main Nada program\"\"\"\n",
        "    parties = na.parties(2)\n",
        "\n",
        "    my_model = MyModel()\n",
        "\n",
        "    my_model.load_state_from_network(\n",
        "        \"my_model\",\n",
        "        parties[0],\n",
        "        na.SecretRational,\n",
        "    )\n",
        "\n",
        "    my_input = na.array(\n",
        "        INPUT_DIMS,\n",
        "        parties[1],\n",
        "        \"my_input\",\n",
        "        na.SecretRational,\n",
        "    )\n",
        "\n",
        "    result = my_model(my_input)\n",
        "\n",
        "    return result.output(parties[1], \"my_output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h76SQK9jJD16",
        "outputId": "0994929f-5bc5-4388-dd78-0419a7a8b45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building program: \u001b[1m\u001b[32minference\u001b[39m\u001b[0m\n",
            "\u001b[1;32mBuild complete!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!nada build"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Deploy our Nada program"
      ],
      "metadata": {
        "id": "ejRPKApOV0ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nada_numpy.client as na_client\n",
        "from dotenv import load_dotenv\n",
        "from nillion_python_helpers import create_nillion_client, create_payments_config, get_quote, get_quote_and_pay, pay_with_quote\n",
        "import py_nillion_client as nillion\n",
        "from py_nillion_client import NodeKey, UserKey\n",
        "from cosmpy.aerial.client import LedgerClient\n",
        "from cosmpy.aerial.wallet import LocalWallet\n",
        "from cosmpy.crypto.keypairs import PrivateKey"
      ],
      "metadata": {
        "id": "O0pO9v3yX8w1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U3QDAa_iJD16"
      },
      "outputs": [],
      "source": [
        "home = os.getenv(\"HOME\")\n",
        "load_dotenv(f\"{home}/.config/nillion/nillion-devnet.env\")\n",
        "\n",
        "cluster_id = os.getenv(\"NILLION_CLUSTER_ID\")\n",
        "grpc_endpoint = os.getenv(\"NILLION_NILCHAIN_GRPC\")\n",
        "chain_id = os.getenv(\"NILLION_NILCHAIN_CHAIN_ID\")\n",
        "seed = \"my_seed\"\n",
        "\n",
        "userkey = UserKey.from_seed((seed))\n",
        "nodekey = NodeKey.from_seed((seed))\n",
        "\n",
        "client = create_nillion_client(userkey, nodekey)\n",
        "party_id = client.party_id\n",
        "user_id = client.user_id\n",
        "\n",
        "party_names = na_client.parties(2)\n",
        "program_name = \"inference\"\n",
        "program_mir_path = f\"target/{program_name}.nada.bin\"\n",
        "\n",
        "payments_config = create_payments_config(chain_id, grpc_endpoint)\n",
        "payments_client = LedgerClient(payments_config)\n",
        "payments_wallet = LocalWallet(\n",
        "    PrivateKey(bytes.fromhex(os.getenv(\"NILLION_NILCHAIN_PRIVATE_KEY_0\"))),\n",
        "    prefix=\"nillion\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote_store_program = await get_quote(\n",
        "    client, nillion.Operation.store_program(program_mir_path), cluster_id\n",
        ")\n",
        "\n",
        "receipt_store_program = await pay_with_quote(\n",
        "    quote_store_program, payments_wallet, payments_client\n",
        ")\n",
        "\n",
        "action_id = await client.store_program(\n",
        "    cluster_id, program_name, program_mir_path, receipt_store_program\n",
        ")\n",
        "\n",
        "program_id = f\"{user_id}/{program_name}\"\n",
        "\n",
        "print(\"Program deployed!\")\n",
        "print(\"program_id:\", program_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdi5a1rEX1EH",
        "outputId": "64712b40-8ac3-4582-c1d7-c1d93b2c2d1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting quote for operation...\n",
            "Submitting payment receipt 2 unil, tx hash BBBFE5266924F8E6FEEF55D07001E21D4103092E981296462559F5F3362E80BE\n",
            "Program deployed!\n",
            "program_id: 3rgqxWd47e171EUwe4RXP9hm45tmoXfuF8fC52S7jcFoQTnU8wPiL7hqWzyV1muak6bEg7iWhudwg4t2pM9XnXcp/inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Provide data"
      ],
      "metadata": {
        "id": "XsAIUyNWZKUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nada_numpy as na\n",
        "from nada_ai.client import TorchClient"
      ],
      "metadata": {
        "id": "2hk3D9M7p7VG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "permissions = nillion.Permissions.default_for_user(client.user_id)\n",
        "permissions.add_compute_permissions({client.user_id: {program_id}})"
      ],
      "metadata": {
        "id": "hpWMLCt4rQcG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = TorchClient(my_model)\n",
        "model_secrets = nillion.NadaValues(\n",
        "    model_client.export_state_as_secrets(\"my_model\", na.SecretRational)\n",
        ")\n",
        "\n",
        "receipt_store_model = await get_quote_and_pay(\n",
        "    client,\n",
        "    nillion.Operation.store_values(model_secrets, ttl_days=1),\n",
        "    payments_wallet,\n",
        "    payments_client,\n",
        "    cluster_id,\n",
        ")\n",
        "\n",
        "model_store_id = await client.store_values(cluster_id, model_secrets, permissions, receipt_store_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J494MtSJrPZ-",
        "outputId": "81d69ead-3876-4d3c-db19-9a202137139c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting quote for operation...\n",
            "Quote cost is 13922 unil\n",
            "Submitting payment receipt 13922 unil, tx hash C9F3EBE12D3C259FFD2B8EB35350A0A4D9C549727F2E4A149D2052E5B75B36C1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: üìù provide your own input data\n",
        "input_data = np.ones((7,))\n",
        "\n",
        "my_input = na_client.array(input_data, \"my_input\", na.SecretRational)\n",
        "input_secrets = nillion.NadaValues(my_input)\n",
        "\n",
        "receipt_store_data = await get_quote_and_pay(\n",
        "    client,\n",
        "    nillion.Operation.store_values(input_secrets, ttl_days=1),\n",
        "    payments_wallet,\n",
        "    payments_client,\n",
        "    cluster_id,\n",
        ")\n",
        "\n",
        "data_store_id = await client.store_values(cluster_id, input_secrets, permissions, receipt_store_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNOZg3RWrMqm",
        "outputId": "ac1e5ac6-c0aa-4ac3-95e1-68f98569bd6e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting quote for operation...\n",
            "Quote cost is 674 unil\n",
            "Submitting payment receipt 674 unil, tx hash 32168C1B1D32D1603F151C47DD0293B49D9AD19E6CFE3F65340EA01675324AD7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Run inference"
      ],
      "metadata": {
        "id": "hi2xQFuxrx9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_bindings = nillion.ProgramBindings(program_id)\n",
        "\n",
        "for party_name in party_names:\n",
        "    compute_bindings.add_input_party(party_name, party_id)\n",
        "\n",
        "compute_bindings.add_output_party(party_names[-1], party_id)"
      ],
      "metadata": {
        "id": "m0H-RZC4rWTm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computation_time_secrets = nillion.NadaValues({})\n",
        "\n",
        "receipt_compute = await get_quote_and_pay(\n",
        "    client,\n",
        "    nillion.Operation.compute(program_id, computation_time_secrets),\n",
        "    payments_wallet,\n",
        "    payments_client,\n",
        "    cluster_id,\n",
        ")\n",
        "\n",
        "_ = await client.compute(\n",
        "    cluster_id,\n",
        "    compute_bindings,\n",
        "    [model_store_id, data_store_id],\n",
        "    computation_time_secrets,\n",
        "    receipt_compute,\n",
        ")\n",
        "\n",
        "while True:\n",
        "    compute_event = await client.next_compute_event()\n",
        "    if isinstance(compute_event, nillion.ComputeFinishedEvent):\n",
        "        print(f\"‚úÖ Compute complete for compute_id {compute_event.uuid}\")\n",
        "        result = compute_event.result.value\n",
        "        break\n",
        "\n",
        "result = {\n",
        "    key: na_client.float_from_rational(value)\n",
        "    for key, value in result.items()\n",
        "}\n",
        "print(\"Result is\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EFX13Jer7KQ",
        "outputId": "c2da2b65-2831-44de-cd94-81c45ef5ceda"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting quote for operation...\n",
            "Quote cost is 388 unil\n",
            "Submitting payment receipt 388 unil, tx hash 92FEB37AC48304A94A49C47431324903161280795FDDCFF64572CABB3B268A15\n",
            "‚úÖ Compute complete for compute_id 3b8b0293-a7a0-49ec-8821-f32913ddfd80\n",
            "Result is {'my_output_0': -0.1307373046875}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}